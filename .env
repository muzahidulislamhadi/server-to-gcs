# ============================================================================
# GCS ENTERPRISE TRANSFER CONFIGURATION
# ============================================================================
# Production-ready configuration for Google Cloud Storage transfers
# Supports both individual files and directories
# 
# QUICK START:
# 1. Set your GCP_PROJECT_ID, GCS_BUCKET_NAME, and SOURCE_PATH below
# 2. Run: chmod +x gcs_enterprise_transfer.sh
# 3. Run: ./gcs_enterprise_transfer.sh
#
# The script will handle everything else automatically!
# ============================================================================

# ============================================================================
# REQUIRED SETTINGS - MUST BE CONFIGURED BEFORE FIRST RUN
# ============================================================================

# Your Google Cloud Project ID
# Find this in your GCP Console or run: gcloud config get-value project
GCP_PROJECT_ID="your-project-id"

# Target GCS bucket name (bucket will be created if it doesn't exist)
# Must be globally unique, use lowercase letters, numbers, hyphens
GCS_BUCKET_NAME="your-unique-bucket-name"

# Source path - can be EITHER a single file OR a directory
# Examples:
#   Single file:    /home/user/important-file.zip
#   Directory:      /mnt/volume_nyc1_02/streams
#   Local folder:   /home/user/documents
#   Network mount:  /mnt/nfs/shared/data
SOURCE_PATH="/mnt/volume_nyc1_02/streams"

# ============================================================================
# GOOGLE CLOUD SETTINGS
# ============================================================================

# Bucket location (choose closest to your data source for best performance)
# Options: us-central1, us-east1, us-west1, europe-west1, asia-east1, etc.
GCS_BUCKET_LOCATION="us-central1"

# Storage class (affects cost and access patterns)
# Options: STANDARD, NEARLINE, COLDLINE, ARCHIVE
GCS_STORAGE_CLASS="STANDARD"

# ============================================================================
# AUTHENTICATION (Optional)
# ============================================================================

# Service Account Key File (for automated/server environments)
# If not set, the script will use interactive browser-based authentication
# Download from: GCP Console > IAM & Admin > Service Accounts
# GOOGLE_APPLICATION_CREDENTIALS="/path/to/service-account-key.json"

# ============================================================================
# PERFORMANCE AND CONCURRENCY SETTINGS
# ============================================================================

# Maximum parallel upload processes (default: 50)
# Higher = faster transfers but more system resources
# Recommendations:
#   - Small files (< 1MB): 50-100
#   - Large files (> 100MB): 10-25
#   - Very large files (> 1GB): 5-10
MAX_PARALLEL_PROCESSES=50

# Upload chunk size for large files (default: 100M)
# Larger chunks = fewer API calls but more memory usage
# Options: 1M, 10M, 50M, 100M, 200M, 500M, 1G, 2G
CHUNK_SIZE="100M"

# Maximum retry attempts for failed operations (default: 5)
MAX_RETRY_ATTEMPTS=5

# Base delay for exponential backoff retries in seconds (default: 2)
# Actual delay = RETRY_BASE_DELAY * (2 ^ attempt_number)
RETRY_BASE_DELAY=2

# Bandwidth limit (optional) - prevents overwhelming your network
# Examples: "50M" = 50 MB/s, "1G" = 1 GB/s
# Leave empty for unlimited bandwidth
BANDWIDTH_LIMIT=""

# ============================================================================
# TRANSFER OPTIONS
# ============================================================================

# Preserve file timestamps and metadata (recommended: true)
PRESERVE_METADATA=true

# Verify transfer integrity using checksums (recommended: true)
# Ensures data corruption is detected
VERIFY_CHECKSUMS=true

# Delete source files after successful transfer (DANGER: default false)
# WARNING: Only enable if you're absolutely certain about data safety
# Recommended: Keep false and delete manually after verification
DELETE_SOURCE_AFTER_TRANSFER=false

# Enable resume for interrupted transfers (recommended: true)
ENABLE_RESUME=true

# ============================================================================
# FILE FILTERING
# ============================================================================

# File exclusion patterns (space-separated glob patterns)
# Files matching these patterns will be skipped
# Common examples for different use cases:
#   System files: "*.tmp *.log .DS_Store *.swp Thumbs.db"
#   Development: "node_modules __pycache__ .git *.pyc *.class"
#   Media editing: "*.tmp *.cache *.preview"
EXCLUDE_PATTERNS="*.tmp *.log .DS_Store *.swp"

# Include only specific file patterns (optional, space-separated)
# If specified, ONLY files matching these patterns will be transferred
# Examples:
#   Images only: "*.jpg *.jpeg *.png *.gif *.bmp *.tiff"
#   Documents: "*.pdf *.doc *.docx *.xls *.xlsx *.ppt *.pptx"
#   Media: "*.mp4 *.avi *.mov *.mkv *.mp3 *.wav *.flac"
#   Archives: "*.zip *.tar *.gz *.bz2 *.7z *.rar"
INCLUDE_PATTERNS=""

# Minimum file size to transfer (optional)
# Files smaller than this will be skipped
# Examples: "1K", "100K", "1M", "10M"
MIN_FILE_SIZE=""

# Maximum file size to transfer (optional)
# Files larger than this will be skipped
# Examples: "100M", "1G", "5G", "10G"
MAX_FILE_SIZE=""

# ============================================================================
# LOGGING AND MONITORING
# ============================================================================

# Log level controls verbosity
# DEBUG: Everything (very detailed, use for troubleshooting)
# INFO:  Normal operations (recommended for most users)
# WARN:  Only warnings and errors
# ERROR: Only errors
LOG_LEVEL="INFO"

# Enable detailed transfer metrics and statistics (recommended: true)
# Creates JSON files with performance data
ENABLE_METRICS=true

# ============================================================================
# NOTIFICATIONS
# ============================================================================

# Enable notifications when transfer completes (default: false)
ENABLE_NOTIFICATIONS=false

# Webhook URL for notifications (Slack, Discord, Microsoft Teams, etc.)
# Slack: Create an Incoming Webhook in your Slack workspace
# Discord: Create a webhook in your Discord channel settings
# NOTIFICATION_WEBHOOK_URL="https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"

# Email notifications (requires system mail capability)
# NOTIFICATION_EMAIL="admin@yourcompany.com"

# ============================================================================
# ADVANCED GSUTIL CONFIGURATION
# ============================================================================

# Parallel composite upload threshold (default: 150M)
# Files larger than this use parallel composite uploads
GSUTIL_PARALLEL_COMPOSITE_UPLOAD_THRESHOLD="150M"

# Parallel thread count per process (default: 10)
# More threads can improve performance for many small files
GSUTIL_PARALLEL_THREAD_COUNT=10

# Resumable upload threshold (default: 8M)
# Files larger than this use resumable uploads (can be resumed if interrupted)
GSUTIL_RESUMABLE_THRESHOLD="8M"

# Custom GCS endpoint (advanced users only)
# For testing, private clouds, or special configurations
# CUSTOM_GCS_ENDPOINT="storage.googleapis.com"

# ============================================================================
# SYSTEM RESOURCE LIMITS (Optional)
# ============================================================================

# Maximum memory usage (optional system protection)
# Examples: "2G", "4G", "8G", "512M"
# Leave empty for no limit
MAX_MEMORY_USAGE=""

# Maximum CPU usage percentage (1-100, optional)
# Limits CPU usage to prevent system overload
# Leave empty for no limit
MAX_CPU_USAGE=""

# Process priority (nice level: -20 to 19, default: 0)
# Negative values = higher priority (requires root)
# Positive values = lower priority (more system friendly)
# 0 = normal priority
PROCESS_NICE_LEVEL=0

# ============================================================================
# EXAMPLE CONFIGURATIONS
# ============================================================================

# HIGH PERFORMANCE SETUP (Fast network, powerful server):
# MAX_PARALLEL_PROCESSES=100
# CHUNK_SIZE="200M"
# GSUTIL_PARALLEL_THREAD_COUNT=20

# CONSERVATIVE SETUP (Limited resources, shared server):
# MAX_PARALLEL_PROCESSES=10
# CHUNK_SIZE="50M"
# GSUTIL_PARALLEL_THREAD_COUNT=5
# BANDWIDTH_LIMIT="100M"

# LARGE FILE SETUP (Few very large files):
# MAX_PARALLEL_PROCESSES=5
# CHUNK_SIZE="1G"
# GSUTIL_PARALLEL_COMPOSITE_UPLOAD_THRESHOLD="500M"

# SMALL FILE SETUP (Many small files):
# MAX_PARALLEL_PROCESSES=100
# CHUNK_SIZE="10M"
# GSUTIL_PARALLEL_THREAD_COUNT=25

# ============================================================================
# SECURITY NOTES
# ============================================================================

# 1. This .env file contains sensitive configuration
#    - Add it to .gitignore if using version control
#    - Set appropriate file permissions: chmod 600 .env

# 2. Service Account Key Security:
#    - Store key files securely with restricted permissions
#    - Use principle of least privilege for service accounts
#    - Rotate keys regularly

# 3. For production use:
#    - Test thoroughly with --dry-run first
#    - Enable notifications for monitoring
#    - Keep DELETE_SOURCE_AFTER_TRANSFER=false until fully confident
#    - Monitor logs and metrics

# ============================================================================
# TROUBLESHOOTING
# ============================================================================

# Common issues and solutions:

# 1. "Permission denied" errors:
#    - Check GCP project permissions
#    - Verify service account has Storage Admin role
#    - Run: gcloud auth list to check authentication

# 2. "Bucket not found" errors:
#    - Verify bucket name is correct and unique
#    - Check bucket location matches your project
#    - Ensure bucket exists or script has permission to create it

# 3. Slow transfers:
#    - Increase MAX_PARALLEL_PROCESSES gradually
#    - Adjust CHUNK_SIZE based on average file sizes
#    - Check network bandwidth and system resources

# 4. Out of memory errors:
#    - Reduce MAX_PARALLEL_PROCESSES
#    - Decrease CHUNK_SIZE
#    - Set MAX_MEMORY_USAGE limit

# 5. Authentication issues:
#    - Delete ~/.config/gcloud and re-authenticate
#    - Check service account key file path and permissions
#    - Verify project ID is correct

# For more help, run: ./gcs_enterprise_transfer.sh --help
# Enable debug logging: LOG_LEVEL="DEBUG"
